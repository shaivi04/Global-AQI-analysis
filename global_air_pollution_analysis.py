# -*- coding: utf-8 -*-
"""Global_Air_Pollution_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l799tkjfEDKMuwJeKLsdizdEGvCsyndJ

# **MINOR PROJECT**

---

# **TASK 1** - Exploratory Data Analysis

<-----------------------Question 1----------------------------->
"""

#----------code

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

data = pd.read_csv('global air pollution dataset.csv')
data.head()

missing_values = data.isna().any()
print(missing_values)

data.isnull().sum()

data.info()

data

"""23463 rows Ã— 12 columns"""

data.dropna(inplace = True)

data.isnull().sum()

data.groupby('Country').count().sort_values(by = 'City',ascending=False)

"""In the dataset, there are two columns ( Country and City) which have missing values.

<-----------------------Question 2----------------------------->
"""

#--------------code
#Plot the distplot of 'AQI Value' vs 'AQI Category'.(kind-'kde')

sns.kdeplot(data=data,x= "AQI Value", hue="AQI Category")

"""Summarizing your analysis and observations

We use kdeplot() to create a KDE plot.
The 'hue' attribute allows us to differentiate and visualize additional categorical data.

"""





"""<-----------------------Question 3----------------------------->"""

#----------code
#Plot a stacked bar graph of 'Ozone AQI Value' vs 'AQI Category'.

grouped_data = data.groupby('AQI Category')['Ozone AQI Value'].sum()


categories = grouped_data.index
values = grouped_data.values

plt.bar(categories, values)                     #bar graph
plt.xlabel('AQI Category')
plt.ylabel('Sum of Ozone AQI Value')
plt.title('Stacked Bar Graph: Ozone AQI Value vs AQI Category')


plt.xticks(rotation=45)                      #to rotate x axis values
plt.show()

"""Summarizing your analysis and observation"""





"""<-----------------------Question 4----------------------------->"""

#--------------code

#Show the list of cities without a stated country. Fill the missing columns with 'Unknown'

cities_without_country = data[data['Country'].isna()]
print(cities_without_country['City'])

cities_without_country['Country'] = cities_without_country['Country'].fillna('Unknown')

"""Summarizing your analysis and observations

<-----------------------Question 5----------------------------->
"""

#----------code

most_representated = data['Country'].value_counts()


sorted_countries = most_representated.sort_values(ascending=False)


N = 20
top_countries = sorted_countries[:N]

plt.bar(top_countries.index, top_countries.values)
plt.xlabel('Count')
plt.ylabel('Country')
plt.title('Top {} Most Represented Countries'.format(N))

#plt.subplots_adjust(bottom=0.2)  # Increase the bottom margin to provide more space for the xlabel

plt.xticks(rotation=45)  # Rotate the labels by 45 degrees


plt.show()

"""Summarizing your analysis and observation"""





"""# **TASK 2** - Classification/Regression

Perform following steps on the same dataset which you used for EDA.
> - Data Preprocessing (as per requirement)
> - Feature Engineering
> - Split dataset in train-test (80:20 ratio)
> - Model selection
> - Model training
> - Model evaluation
> - Fine-tune the Model
> - Make predictions

Summarize your model's performance by evaluation metrices
"""

# pip install lazypredict

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
#from lazypredict.Supervised import LazyRegressor
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier

data['Max Value'] = data[['NO2 AQI Value', 'CO AQI Value', 'PM2.5 AQI Value', 'CO AQI Value']].max(axis=1)

label_encoder = LabelEncoder()
data['AQI Category'] = label_encoder.fit_transform(data['AQI Category'])

features = ['Max Value']  # Using the new 'Max Value' feature
X = data[features]
y = data['AQI Category']

joblib.dump(label_encoder, 'label_encoder.pkl')

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# # Initialize Logistic Regression with the one-vs-all strategy
# model = LogisticRegression(multi_class='ovr')

# # Train the model
# model.fit(X_train, y_train)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
rf_model.fit(X_train, y_train)

# Predict and evaluate
y_pred = rf_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print("Accuracy:", accuracy)

y_pred = model.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix,accuracy_score

# Evaluate the model's performance
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Classification Report:\n", report)



import pandas as pd

# Example new data
new_data = pd.DataFrame({
    'CO AQI Value': [15],
    'Ozone AQI Value': [20],
    'NO2 AQI Value': [8],
    'PM2.5 AQI Value': [42]
})

# Find the maximum AQI value from the new data
max_data_value = new_data.max(axis=1).values[0]  # axis=1 to get the max across columns for each row

max_data_value_reshaped = [[max_data_value]]  # Reshape to 2D array for prediction

predicted_category = rf_model.predict(max_data_value_reshaped)

# Decode the predicted label
predicted_category_label = label_encoder.inverse_transform(predicted_category)

print("Predicted AQI Category:", predicted_category_label[0])

data.describe()

data.info()

import joblib

joblib_file = "rf_model.pkl"
joblib.dump(rf_model, joblib_file)
print(f"Best model: {rf_model} saved as {joblib_file}")

!pip freeze | grep joblib
!pip freeze | grep scikit-learn









